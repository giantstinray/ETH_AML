{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb \n",
    "import catboost as cat\n",
    "from cubist import Cubist\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import (\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    feature_selection,\n",
    "    impute,\n",
    "    linear_model,\n",
    "    model_selection,\n",
    "    pipeline,\n",
    "    preprocessing,\n",
    "    svm,\n",
    ")\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from pyod.models.ecod import ECOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X_train = pd.read_csv('X_train_rf_20.csv', usecols=lambda column: column != 'id')\n",
    "    y_train = pd.read_csv('y_train.csv', usecols=lambda column: column != 'id')\n",
    "    X_test = pd.read_csv('X_test_rf_20.csv', usecols=lambda column: column != 'id')\n",
    "    sample = pd.read_csv('sample.csv')\n",
    "    return X_train, y_train, X_test, sample\n",
    "\n",
    "def outlier(X_train, y_train):\n",
    "    model = pipeline.make_pipeline(\n",
    "        preprocessing.RobustScaler(),\n",
    "        # impute.SimpleImputer(strategy='median'),\n",
    "        decomposition.PCA(n_components=2),\n",
    "        ensemble.IsolationForest(contamination=0.0455)\n",
    "    )\n",
    "    mask = (model.fit_predict(X_train) > 0).astype(int)==1\n",
    "    X_train= pd.DataFrame(X_train[mask]).reset_index(drop=True)\n",
    "    y_train= pd.DataFrame(y_train[mask]).reset_index(drop=True)\n",
    "    return X_train, y_train\n",
    "\n",
    "def imput(X_train, X_test):\n",
    "    model = pipeline.make_pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        impute.SimpleImputer(strategy='median'),\n",
    "    )\n",
    "    X_train = model.fit_transform(X_train)\n",
    "    X_test = model.transform(X_test)\n",
    "    return X_train, X_test              \n",
    "\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    model = pipeline.make_pipeline(\n",
    "        feature_selection.VarianceThreshold(),\n",
    "        feature_selection.SelectKBest(score_func=feature_selection.f_regression, k=195),\n",
    "        feature_selection.SelectFromModel(linear_model.Lasso(0.075))\n",
    "    )              \n",
    "    model.fit(X_train, y_train)\n",
    "    X_train = model.transform(X_train)\n",
    "    X_test = model.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def make_submission(model, X_train, y_train, X_test, sample):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    sample['y'] = y_test_pred\n",
    "    sample.to_csv(\"submission.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original shapes of X_train, y_train and X_test are:  (1212, 832) (1212, 1) (776, 832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+04, tolerance: 1.006e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed shapes of X_train, y_train and X_test are:  (1156, 133) (1156, 1) (776, 133)\n",
      "0.677244228067251 0.02507546267455542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:865: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_train_original, y_train_original, X_test_original, sample = load_data()\n",
    "print('The original shapes of X_train, y_train and X_test are: ', \n",
    "      X_train_original.shape, y_train_original.shape, X_test_original.shape)\n",
    "\n",
    "X_train, y_train = outlier(X_train_original, y_train_original)\n",
    "# X_train, X_test = imput(X_train, X_test_original)\n",
    "X_train, X_test = select_features(X_train, y_train, X_test_original)\n",
    "print('The preprocessed shapes of X_train, y_train and X_test are: ', \n",
    "      X_train.shape, y_train.shape, X_test.shape)\n",
    "\n",
    "model = pipeline.make_pipeline(\n",
    "    ensemble.StackingRegressor(\n",
    "        estimators=[\n",
    "            (\"svr\", svm.SVR(C=65.0, epsilon=1e-05, kernel='rbf')),\n",
    "            (\"etr\", ensemble.ExtraTreesRegressor()),\n",
    "            ('lgb', lgb.LGBMRegressor(verbose=0)),\n",
    "            (\"gbm\", ensemble.GradientBoostingRegressor(learning_rate=0.085)),\n",
    "            ('cat', cat.CatBoostRegressor(verbose=0)),\n",
    "            # ('cubist', Cubist(verbose=0, n_committees=5, cv=10, auto=True))\n",
    "\n",
    "        ],\n",
    "        final_estimator=linear_model.ElasticNet(),\n",
    "    )\n",
    ")\n",
    "score = model_selection.cross_val_score(model, X_train, y_train, cv=5, n_jobs=6)\n",
    "print(score.mean(), score.std()) \n",
    "\n",
    "make_submission(model, X_train, y_train, X_test, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KFold\n",
    "kf = model_selection.KFold(n_splits=20, shuffle=True, random_state=88)\n",
    "\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "best_r2_score = -np.inf  # Initialize best R² to a very low value\n",
    "best_model = None  # To store the best model\n",
    "best_scaler = None  # To store the scaler for the best model\n",
    "\n",
    "# Loop through each fold\n",
    "for fold_num, (train_index, val_index) in enumerate(kf.split(X_train), start=1):\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)  # Fit and transform on training data\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "\n",
    "    # Create and fit the model\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # model = stacked_regressor\n",
    "\n",
    "    # model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Calculate RMSE and R²\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
    "    r2 = r2_score(y_val_fold, y_pred)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold {fold_num}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    # Keep track of the best model based on R² score\n",
    "    if r2 > best_r2_score:\n",
    "        best_r2_score = r2\n",
    "        best_model = model  # Store the model with the best R²\n",
    "        best_scaler = scaler  # Store the corresponding scaler\n",
    "\n",
    "# Print the average RMSE and R² across all folds\n",
    "print(f\"\\nAverage RMSE: {np.mean(rmse_scores):.4f}\")\n",
    "print(f\"Average R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"\\nBest R² Score: {best_r2_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: Verbose\n"
     ]
    }
   ],
   "source": [
    "# Use the best model and corresponding scaler to predict on X_test\n",
    "X_test_standardized = best_scaler.transform(X_test)  # Standardize X_test using the best scaler\n",
    "y_test_pred = best_model.predict(X_test_standardized)\n",
    "\n",
    "sample['y'] = y_test_pred\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

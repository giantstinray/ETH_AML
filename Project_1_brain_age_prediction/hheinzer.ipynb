{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import (\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    feature_selection,\n",
    "    impute,\n",
    "    linear_model,\n",
    "    model_selection,\n",
    "    pipeline,\n",
    "    preprocessing,\n",
    "    svm,\n",
    ")\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic\n",
    "\n",
    "# from explore import plot_outliers\n",
    "\n",
    "\n",
    "def main():\n",
    "    X_train, y_train, X_test = load_data()\n",
    "    print(X_train.shape, y_train.shape, X_test.shape)\n",
    "\n",
    "    X_train, y_train = remove_outliers(X_train, y_train, X_test)\n",
    "    X_train, X_test = preprocess(X_train, X_test)\n",
    "    X_train, X_test = select_features(X_train, y_train, X_test)\n",
    "    print(X_train.shape, y_train.shape, X_test.shape)\n",
    "\n",
    "    model = pipeline.make_pipeline(\n",
    "        ensemble.StackingRegressor(\n",
    "            estimators=[\n",
    "                (\"svr\", svm.SVR(C=60.0, epsilon=1e-05, kernel='rbf')),\n",
    "                (\"gbm\", ensemble.GradientBoostingRegressor(learning_rate=0.095)),\n",
    "                (\"etr\", ensemble.ExtraTreesRegressor()),\n",
    "                ('lgb', lgb.LGBMRegressor())\n",
    "\n",
    "            ],\n",
    "            final_estimator=linear_model.Ridge(),\n",
    "        )\n",
    "    )\n",
    "    score = model_selection.cross_val_score(model, X_train, y_train, cv=5, n_jobs=6)\n",
    "    print(score.mean(), score.std())  # 0.6844646263431688 0.02663668357699777\n",
    "\n",
    "    create_submission(model, X_train, y_train, X_test)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    X_train = np.genfromtxt(\"X_train.csv\", delimiter=\",\", skip_header=1)[:, 1:]\n",
    "    y_train = np.genfromtxt(\"y_train.csv\", delimiter=\",\", skip_header=1)[:, 1:]\n",
    "    X_test = np.genfromtxt(\"X_test.csv\", delimiter=\",\", skip_header=1)[:, 1:]\n",
    "    y_train = y_train.ravel()\n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "\n",
    "def remove_outliers(X_train, y_train, X_test):\n",
    "    model = pipeline.make_pipeline(\n",
    "        preprocessing.RobustScaler(),\n",
    "        impute.SimpleImputer(strategy=\"median\"),\n",
    "        decomposition.PCA(n_components=2),\n",
    "        ensemble.IsolationForest(contamination=0.0455),  # type: ignore\n",
    "    )\n",
    "    pred = model.fit_predict(X_train)\n",
    "    # plot_outliers(model[:3].transform(X_train), model[:3].transform(X_test), pred)\n",
    "    X_train, y_train = X_train[pred > 0], y_train[pred > 0]\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def preprocess(X_train, X_test):\n",
    "    model = pipeline.make_pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        impute.SimpleImputer(strategy=\"median\"),\n",
    "    )\n",
    "    X_train = model.fit_transform(X_train)\n",
    "    X_test = model.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    model = pipeline.make_pipeline(\n",
    "        feature_selection.VarianceThreshold(),\n",
    "        feature_selection.SelectKBest(score_func=feature_selection.f_regression, k=195),\n",
    "        feature_selection.SelectFromModel(linear_model.Lasso(0.1)),\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    X_train = model.transform(X_train)\n",
    "    X_test = model.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def create_submission(model, X_train, y_train, X_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred = np.vstack((np.arange(X_test.shape[0]), pred)).T\n",
    "    np.savetxt(\"submission_test.csv\", pred, delimiter=\",\", header=\"id,y\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 832) (1212,) (776, 832)\n",
      "(1156, 81) (1156,) (776, 81)\n",
      "0.687761286777815 0.030280854381405153\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20655\n",
      "[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score 69.978374\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20655\n",
      "[LightGBM] [Info] Number of data points in the train set: 924, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score 69.954545\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20655\n",
      "[LightGBM] [Info] Number of data points in the train set: 925, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score 70.061622\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20655\n",
      "[LightGBM] [Info] Number of data points in the train set: 925, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score 69.870270\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20655\n",
      "[LightGBM] [Info] Number of data points in the train set: 925, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score 69.870270\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20655\n",
      "[LightGBM] [Info] Number of data points in the train set: 925, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score 70.135135\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

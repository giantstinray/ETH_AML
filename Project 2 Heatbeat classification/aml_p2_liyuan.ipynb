{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lygitdata/aml_project/blob/main/project2/aml_p2_liyuan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W7kED4XJhfM"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-kzINuVTpkVx"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import biosppy.signals.ecg as ecg\n",
    "import biosppy\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import kurtosis, skew\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from imblearn import over_sampling, pipeline\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import ensemble, model_selection, preprocessing\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU2FJyaTJlzc"
   },
   "source": [
    "# Import dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cLKvp5nNLLGY"
   },
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    X_train = pd.read_csv(train_path, index_col=\"id\")\n",
    "    y_train = X_train.iloc[:, 0]\n",
    "    X_train = X_train.iloc[:, 1:]\n",
    "    X_test = pd.read_csv(test_path, index_col=\"id\")\n",
    "    return transform_data(X_train), y_train.values, transform_data(X_test)\n",
    "\n",
    "def transform_data(df):\n",
    "    return np.array([row.dropna().to_numpy(dtype='float32') for _, row in df.iterrows()], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2fuwsyRbLwb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_raw shape:  (5117,) \n",
      "y_train_raw shape (5117,) \n",
      "X_test_raw shape (3411,)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, y_train_raw, X_test_raw = load_data(\n",
    "    train_path = \"train.csv\",\n",
    "    test_path = \"test.csv\"\n",
    ")\n",
    "print(\n",
    "    \"X_train_raw shape: \",\n",
    "    X_train_raw.shape,\n",
    "    \"\\ny_train_raw shape\",\n",
    "    y_train_raw.shape,\n",
    "    \"\\nX_test_raw shape\",\n",
    "    X_test_raw.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_HB-f2gmDlQ"
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9QkBxVzcOJS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5117 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Function to extract features from a single raw ECG signal\n",
    "def _extract_features(signal):\n",
    "    # Use biosppy to process the ECG signal and extract features\n",
    "    out = biosppy.signals.ecg.ecg(signal=signal, sampling_rate=300, show=False)\n",
    "\n",
    "    # Access relevant outputs from the tuple\n",
    "    rpeaks = out[2]  # Indices of R-peaks\n",
    "    heart_rate = out[6]  # Instantaneous heart rate\n",
    "\n",
    "    # Feature vector to store the extracted features\n",
    "    features = []\n",
    "\n",
    "    # Spectral features using FFT (same as before)\n",
    "    clip = signal[rpeaks[0]:rpeaks[-1]]  # Clip signal around R-peaks\n",
    "    freq = np.fft.rfftfreq(len(clip), 1 / 300)  # Frequency bin edges (sampling rate assumed as 300 Hz)\n",
    "    spec = np.abs(np.fft.rfft(clip)) / len(clip)  # Spectral magnitude\n",
    "    freq, spec = binned(freq, spec, 50.0, 100, np.max)  # Bin and apply max function\n",
    "    features += list(spec)\n",
    "\n",
    "    # Autocorrelation of the signal\n",
    "    autocorr = np.correlate(clip, clip, mode=\"full\") / len(clip)\n",
    "    autocorr = autocorr[autocorr.size // 2:]\n",
    "    time = np.linspace(0, len(clip) / 300, len(clip))\n",
    "    time, autocorr = binned(time, autocorr, 1.0, 100, np.mean)\n",
    "    features += list(autocorr)\n",
    "\n",
    "    # Heart rate features (mean, std, median, variance)\n",
    "    features += msmv(heart_rate)\n",
    "\n",
    "    # HRV (Heart Rate Variability) - difference between successive R-peaks (R-R intervals)\n",
    "    rr_intervals = np.diff(rpeaks) / 300  # R-R intervals in seconds\n",
    "    features += msmv(rr_intervals)  # HRV: mean, std, median, variance of R-R intervals\n",
    "\n",
    "    # QRS Duration (can be approximated by the difference between consecutive R-peaks)\n",
    "    qrs_duration = np.diff(rpeaks) / 300  # In seconds\n",
    "    features.append(np.mean(qrs_duration))  # Average QRS duration\n",
    "\n",
    "    # Signal Entropy: Measure of signal complexity (Shannon Entropy)\n",
    "    entropy = signal_entropy(clip)\n",
    "    features.append(entropy)\n",
    "\n",
    "    # Time-domain features: Mean, Standard deviation, Skewness, Kurtosis\n",
    "    features += time_domain_features(clip)\n",
    "\n",
    "    # Return the extracted feature vector\n",
    "    return features\n",
    "\n",
    "# Function to calculate Shannon entropy of a signal\n",
    "def signal_entropy(signal):\n",
    "    prob_density, _ = np.histogram(signal, bins=10, density=True)\n",
    "    prob_density = prob_density[prob_density > 0]  # Remove zero probabilities\n",
    "    entropy = -np.sum(prob_density * np.log(prob_density))  # Shannon entropy\n",
    "    return entropy\n",
    "\n",
    "# Time-domain statistical features (mean, std, skewness, kurtosis)\n",
    "def time_domain_features(signal):\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    skewness = skew(signal)\n",
    "    kurt = kurtosis(signal)\n",
    "    return [mean, std, skewness, kurt]\n",
    "\n",
    "# Binned function for downsampling and applying a function over binned data\n",
    "def binned(x, y, xend, nbins, func):\n",
    "    bx = np.linspace(x[0], xend, nbins + 1)\n",
    "    idx = np.digitize(x, bx) - 1  # Bin assignments\n",
    "    bx = (bx[1:] + bx[:-1]) / 2  # Bin centers\n",
    "    by = np.array([func(y[idx == i]) for i in range(nbins)])  # Apply function to each bin\n",
    "    return bx, by\n",
    "\n",
    "# MSMV function to compute statistical measures\n",
    "def msmv(x):\n",
    "    x = x[~np.isnan(x)]  # Remove NaNs\n",
    "    if len(x) == 0:\n",
    "        return [0, 0, 0, 0]\n",
    "    if len(x) == 1:\n",
    "        return [x[0], 0, x[0], 0]\n",
    "    else:\n",
    "        return [np.mean(x), np.std(x), np.median(x), np.var(x)]\n",
    "\n",
    "def extract_features(X, inverse=False):\n",
    "    # Parallelize using multiprocessing (avoid excessive memory consumption by processing in chunks)\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        Xn = list(tqdm(pool.imap(_extract_features, X), total=len(X)))\n",
    "    return np.array(Xn)\n",
    "\n",
    "# Example of applying the function to X_train_raw and X_test_raw\n",
    "X_train_features = extract_features(X_train_raw)\n",
    "X_test_features = extract_features(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKhY7Y7mjcEl"
   },
   "outputs": [],
   "source": [
    "X_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_B9wNDfje_t"
   },
   "outputs": [],
   "source": [
    "X_test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZoPtkjEuIcQ"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YecKr6dTjmO2"
   },
   "outputs": [],
   "source": [
    "model = pipeline.make_pipeline(\n",
    "    over_sampling.RandomOverSampler(random_state=42),\n",
    "    preprocessing.StandardScaler(),\n",
    "    ensemble.HistGradientBoostingClassifier(l2_regularization=0.2),\n",
    ")\n",
    "score = model_selection.cross_val_score(model, X_train_features, y_train_raw, cv=10, n_jobs=-1)\n",
    "print(score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejMC6PFHkVnb"
   },
   "outputs": [],
   "source": [
    "def create_submission(model, X_train, y_train, X_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred = np.vstack((np.arange(X_test.shape[0]), pred)).T\n",
    "    np.savetxt(\"submission.csv\", pred, delimiter=\",\", header=\"id,y\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7ZTDh4okWi8"
   },
   "outputs": [],
   "source": [
    "create_submission(model, X_train_features, y_train_raw, X_test_features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMjOow7mawLq8spCP80FMq7",
   "include_colab_link": true,
   "mount_file_id": "1CqUKua_qbfR3gNJDGCuFdaz2O3TB_3nN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

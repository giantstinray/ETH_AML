{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lygitdata/aml_project/blob/main/project2/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGfw7IukYeYW"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yD-hZ8l9Ybmd"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import biosppy.signals.ecg as ecg\n",
    "import biosppy\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks, welch\n",
    "from scipy.stats import kurtosis, skew\n",
    "import pywt\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from imblearn import over_sampling, pipeline\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import ensemble, model_selection, preprocessing, svm, linear_model\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Change this path to the folder that has your data\n",
    "fpath = \"aml_p2/data/\"\n",
    "RANDOM_STATE = 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7k2tC0dNYhL9"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SfcAO82VYjRF"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(f\"{fpath}X_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(f\"{fpath}X_test.npy\", allow_pickle=True)\n",
    "y_train = np.load(f\"{fpath}y_train.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx1UdoBtZAtY"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.4221947194719472, 1: 2.8876975169300225, 2: 0.867876526458616, 3: 7.525}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Class labels\n",
    "class_labels = np.unique(y_train)  # Assuming one-hot encoded y_train_updated\n",
    "\n",
    "# Compute weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=class_labels,\n",
    "    y=y_train  # Convert one-hot to class indices\n",
    ")\n",
    "\n",
    "# Convert to dictionary format\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kjsm6LzIZFYp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5117, 359) \n",
      "X_test shape (3411, 359)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"X_train shape: \",\n",
    "    X_train.shape,\n",
    "    \"\\nX_test shape\",\n",
    "    X_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.4221947194719472, 1: 2.8876975169300225, 2: 0.867876526458616, 3: 7.525}\n",
      "X_train shape:  (5117, 359) \n",
      "X_test shape (3411, 359)\n"
     ]
    }
   ],
   "source": [
    "# Replace None with np.nan\n",
    "X_train = np.where(X_train == None, np.nan, X_train)\n",
    "X_test = np.where(X_test == None, np.nan, X_test)\n",
    "\n",
    "# Check for infinity or NaN values in X_train and replace them with a large finite number or the mean of the column\n",
    "X_train = np.nan_to_num(X_train, nan=np.nanmean(X_train), posinf=np.finfo(np.float64).max, neginf=np.finfo(np.float64).min)\n",
    "X_test = np.nan_to_num(X_test, nan=np.nanmean(X_test), posinf=np.finfo(np.float64).max, neginf=np.finfo(np.float64).min)\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n",
    "print(\"X_train shape: \", X_train.shape, \"\\nX_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in X_train: {<class 'numpy.float64'>}\n",
      "Data types in X_test: {<class 'numpy.float64'>}\n",
      "Largest value in X_train: 1.7976931348623157e+308\n",
      "Largest value in X_test: 18054887424.0\n",
      "20 largest values in X_train: [1.79769313e+308 1.79769313e+308 1.79769313e+308 1.79769313e+308\n",
      " 1.79769313e+308 1.79769313e+308 1.79769313e+308 1.79769313e+308\n",
      " 1.79769313e+308 1.79769313e+308 1.79769313e+308 1.79769313e+308\n",
      " 1.79769313e+308 1.79769313e+308 1.79769313e+308 1.79769313e+308\n",
      " 1.79769313e+308 1.79769313e+308 1.79769313e+308 1.79769313e+308]\n",
      "20 largest values in X_test: [4.41139866e+09 4.62249216e+09 4.62445722e+09 4.64018125e+09\n",
      " 4.69550490e+09 5.12602061e+09 5.23699661e+09 5.43251251e+09\n",
      " 5.45307443e+09 6.16422400e+09 6.87561574e+09 7.21413530e+09\n",
      " 7.69713510e+09 7.79243622e+09 8.43129702e+09 8.59020902e+09\n",
      " 9.55752243e+09 1.11652229e+10 1.12790702e+10 1.80548874e+10]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "# Ensure no infinity or too large values\n",
    "X_train = np.nan_to_num(X_train, nan=np.nanmean(X_train), posinf=np.finfo(np.float64).max, neginf=np.finfo(np.float64).min)\n",
    "X_test = np.nan_to_num(X_test, nan=np.nanmean(X_test), posinf=np.finfo(np.float64).max, neginf=np.finfo(np.float64).min)\n",
    "\n",
    "print(\"Data types in X_train:\", set(map(type, X_train.flatten())))\n",
    "print(\"Data types in X_test:\", set(map(type, X_test.flatten())))\n",
    "print(\"Largest value in X_train:\", np.max(X_train))\n",
    "print(\"Largest value in X_test:\", np.max(X_test))\n",
    "# Check the 20 largest values in X_train and X_test\n",
    "largest_values_train = np.sort(X_train.flatten())[-20:]\n",
    "largest_values_test = np.sort(X_test.flatten())[-20:]\n",
    "\n",
    "print(\"20 largest values in X_train:\", largest_values_train)\n",
    "print(\"20 largest values in X_test:\", largest_values_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhB8VtT8Y_25"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VdENCqCBdj08"
   },
   "outputs": [],
   "source": [
    "model = pipeline.make_pipeline(\n",
    "    # over_sampling.RandomOverSampler(random_state=RANDOM_STATE),\n",
    "    preprocessing.StandardScaler(),\n",
    "    ensemble.StackingClassifier(\n",
    "        estimators = [\n",
    "            (\"hgb\", ensemble.HistGradientBoostingClassifier(l2_regularization=0.15, max_iter=400, random_state=0)),\n",
    "            (\"xgb\", XGBRegressor(n_estimators=2000, learning_rate=0.11, max_depth=16, alphha=0.2, verbosity=0, random_state=0)),\n",
    "            (\"lgb\", lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.11, num_leaves=16, num_threads=128, verbose=0, random_state=0)),\n",
    "        ],\n",
    "        final_estimator=linear_model.RidgeClassifierCV()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ifRBoTXAZT4D"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 6 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\fixes.py\", line 85, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 329, in fit\n    Xt, yt = self._fit(X, y, routed_params)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 255, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 1104, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains infinity or a value too large for dtype('float64').\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean F1 score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, score\u001b[38;5;241m.\u001b[39mmean(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStd. F1 score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, score\u001b[38;5;241m.\u001b[39mstd())\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 6 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\fixes.py\", line 85, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 329, in fit\n    Xt, yt = self._fit(X, y, routed_params)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 255, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 1104, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"c:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    }
   ],
   "source": [
    "score = model_selection.cross_val_score(\n",
    "    estimator=model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=6,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"Mean F1 score: \", score.mean(), \"\\nStd. F1 score: \", score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-v_QaA9dfLs"
   },
   "source": [
    "# Generate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ujHT0aqoan6e"
   },
   "outputs": [],
   "source": [
    "def create_submission(model, X_train, y_train, X_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred = np.vstack((np.arange(X_test.shape[0]), pred)).T\n",
    "    np.savetxt(\"submission.csv\", pred, delimiter=\",\", header=\"id,y\", comments=\"\")\n",
    "\n",
    "\n",
    "create_submission(model, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNFswewg8o1/mo3p6VvvSha",
   "include_colab_link": true,
   "mount_file_id": "12CBSzY_EGcvmAOVBXFcGaI9jCbhUpZFj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

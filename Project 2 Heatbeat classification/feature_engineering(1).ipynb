{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lygitdata/aml_project/blob/main/project2/feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W7kED4XJhfM"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-kzINuVTpkVx"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import kurtosis, skew\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import hrvanalysis\n",
    "\n",
    "# Change this path to the folder that has your data\n",
    "fpath = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU2FJyaTJlzc"
   },
   "source": [
    "# Import dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cLKvp5nNLLGY"
   },
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    X_train = pd.read_csv(train_path, index_col=\"id\")\n",
    "    y_train = X_train.iloc[:, 0]\n",
    "    X_train = X_train.iloc[:, 1:]\n",
    "    X_test = pd.read_csv(test_path, index_col=\"id\")\n",
    "    return transform_data(X_train), y_train.values, transform_data(X_test)\n",
    "\n",
    "def transform_data(df):\n",
    "    return np.array([row.dropna().to_numpy(dtype='float32') for _, row in df.iterrows()], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fuwsyRbLwb0",
    "outputId": "a42cf1c6-102f-4942-b18b-74ecaeaf3e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_raw shape:  (5117,) \n",
      "y_train_raw shape (5117,) \n",
      "X_test_raw shape (3411,)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, y_train_raw, X_test_raw = load_data(\n",
    "    train_path = f\"{fpath}train.csv\",\n",
    "    test_path = f\"{fpath}test.csv\"\n",
    ")\n",
    "print(\n",
    "    \"X_train_raw shape: \",\n",
    "    X_train_raw.shape,\n",
    "    \"\\ny_train_raw shape\",\n",
    "    y_train_raw.shape,\n",
    "    \"\\nX_test_raw shape\",\n",
    "    X_test_raw.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_HB-f2gmDlQ"
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9QkBxVzcOJS"
   },
   "outputs": [],
   "source": [
    "def _feature_engineering(signal, method=\"neurokit\"):\n",
    "    # Feature vector to store the extracted features\n",
    "    features = []\n",
    "\n",
    "    try:\n",
    "        # Attempt using the first method\n",
    "        signals, info = nk.ecg_process(\n",
    "            ecg_signal=signal, sampling_rate=300, method=\"neurokit\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Method 'neurokit' failed:\", e)\n",
    "        try:\n",
    "            # Fallback to second method\n",
    "            signals, info = nk.ecg_process(\n",
    "                ecg_signal=signal, sampling_rate=300, method=\"pantompkins1985\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Method 'pantompkins1985' failed:\", e)\n",
    "            try:\n",
    "                # Fallback to third method\n",
    "                signals, info = nk.ecg_process(\n",
    "                    ecg_signal=signal, sampling_rate=300, method=\"hamilton2002\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\"Method 'hamilton2002' failed:\", e)\n",
    "                try:\n",
    "                    # Fallback to fourth method\n",
    "                    signals, info = nk.ecg_process(\n",
    "                        ecg_signal=signal, sampling_rate=300, method=\"elgendi2010\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(\"Method 'elgendi2010' failed:\", e)\n",
    "                    try:\n",
    "                        # Fallback to fifth method\n",
    "                        signals, info = nk.ecg_process(\n",
    "                            ecg_signal=signal, sampling_rate=300, method=\"engzeemod2012\"\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(\"Method 'engzeemod2012' failed:\", e)\n",
    "                        raise ValueError(\n",
    "                            \"All methods failed. Please check the input signal.\"\n",
    "                        )\n",
    "\n",
    "    # Access relevant outputs from the tuple\n",
    "    rpeaks = info[\"ECG_R_Peaks\"]\n",
    "    heart_rate = np.array(signals[\"ECG_Rate\"][info[\"ECG_R_Peaks\"]])\n",
    "\n",
    "    # Feature summary stats vectors:\n",
    "    for key in [\"ECG_P_Peaks\", \"ECG_Q_Peaks\", \"ECG_S_Peaks\", \"ECG_T_Peaks\"]:\n",
    "        idx = np.array(info[key])[~np.isnan(info[key])]\n",
    "        features += summary_stats(idx)\n",
    "        features += summary_stats(np.diff(idx))\n",
    "        features += summary_stats(np.array(signals[\"ECG_Clean\"][idx.astype(int)]))\n",
    "        features += summary_stats(np.diff(signals[\"ECG_Clean\"][idx.astype(int)]))\n",
    "\n",
    "    # PR interval, PR segment, QT interval, ST segment, QRS complex\n",
    "    p_r_int = np.array(signals[\"ECG_P_Onsets\"] - signals[\"ECG_R_Onsets\"])\n",
    "    p_r_seg = np.array(signals[\"ECG_P_Offsets\"] - signals[\"ECG_R_Onsets\"])\n",
    "    q_t_int = np.array(signals[\"ECG_Q_Peaks\"] - signals[\"ECG_T_Offsets\"])\n",
    "    s_t_seg = np.array(signals[\"ECG_S_Peaks\"] - signals[\"ECG_T_Onsets\"])\n",
    "    qrs_cpx = np.array(signals[\"ECG_Q_Peaks\"] - signals[\"ECG_S_Peaks\"])\n",
    "    for item in [p_r_int, p_r_seg, q_t_int, s_t_seg, qrs_cpx]:\n",
    "        features += summary_stats(item[item != 0])\n",
    "\n",
    "    # Spectral features using FFT\n",
    "    clip = signal[rpeaks[0] : rpeaks[-1]]  # Clip signal around R-peaks\n",
    "    freq = np.fft.rfftfreq(len(clip), 1 / 300)\n",
    "    spec = np.abs(np.fft.rfft(clip)) / len(clip)\n",
    "    freq, spec = binned(freq, spec, 50.0, 100, np.max)\n",
    "    features += list(spec)\n",
    "\n",
    "    # Autocorrelation of the signal\n",
    "    autocorr = np.correlate(clip, clip, mode=\"full\") / len(clip)\n",
    "    autocorr = autocorr[autocorr.size // 2 :]\n",
    "    time = np.linspace(0, len(clip) / 300, len(clip))\n",
    "    time, autocorr = binned(time, autocorr, 1.0, 100, np.mean)\n",
    "    features += list(autocorr)\n",
    "\n",
    "    # Heart rate features\n",
    "    features += summary_stats(heart_rate)\n",
    "\n",
    "    # HRV (Heart Rate Variability)\n",
    "    rr_intervals = np.diff(rpeaks) / 300\n",
    "    features += summary_stats(rr_intervals)\n",
    "\n",
    "    # Signal entropy\n",
    "    entropy = signal_entropy(clip)\n",
    "    features.append(entropy)\n",
    "\n",
    "    # Time-domain features\n",
    "    features += time_domain_features(clip)\n",
    "\n",
    "    # New Features\n",
    "    # 1. Normalized RR intervals\n",
    "    rr_normalized = (rr_intervals - np.min(rr_intervals)) / (\n",
    "        np.max(rr_intervals) - np.min(rr_intervals)\n",
    "    )\n",
    "    features += summary_stats(rr_normalized)\n",
    "\n",
    "    # 2. Skewness and Kurtosis of RR intervals\n",
    "    features.append(skew(rr_intervals))\n",
    "    features.append(kurtosis(rr_intervals))\n",
    "\n",
    "    # 3. Peak-to-peak amplitude variability\n",
    "    r_amplitudes = signal[rpeaks]\n",
    "    features.append(np.std(r_amplitudes))\n",
    "\n",
    "    # 4. Median Absolute Deviation (MAD) of Clean ECG\n",
    "    mad_ecg_clean = np.median(\n",
    "        np.abs(signals[\"ECG_Clean\"] - np.median(signals[\"ECG_Clean\"]))\n",
    "    )\n",
    "    features.append(mad_ecg_clean)\n",
    "\n",
    "    # 5. Fraction of low-amplitude peaks\n",
    "    low_amp_fraction = np.sum(r_amplitudes < 0.5 * np.mean(r_amplitudes)) / len(\n",
    "        r_amplitudes\n",
    "    )\n",
    "    features.append(low_amp_fraction)\n",
    "\n",
    "    # 6. Energy of the signal\n",
    "    features.append(np.sum(np.square(signal)))\n",
    "\n",
    "    # 7. Normalized power in frequency bands\n",
    "    vlf_power = np.sum(spec[(freq >= 0.003) & (freq < 0.04)])\n",
    "    lf_power = np.sum(spec[(freq >= 0.04) & (freq < 0.15)])\n",
    "    hf_power = np.sum(spec[(freq >= 0.15) & (freq < 0.4)])\n",
    "    total_power = vlf_power + lf_power + hf_power\n",
    "    features += [\n",
    "        vlf_power / total_power if total_power != 0 else 0,\n",
    "        lf_power / total_power if total_power != 0 else 0,\n",
    "        hf_power / total_power if total_power != 0 else 0,\n",
    "    ]\n",
    "\n",
    "    # 8. Harmonic mean of RR intervals\n",
    "    rr_harmonic_mean = len(rr_intervals) / np.sum(1.0 / rr_intervals)\n",
    "    features.append(rr_harmonic_mean)\n",
    "\n",
    "    # 9. Baseline wander amplitude\n",
    "    baseline = nk.signal_filter(signal, sampling_rate=300, lowcut=0.5, method=\"butter\")\n",
    "    baseline_wander_amplitude = np.max(baseline) - np.min(baseline)\n",
    "    features.append(baseline_wander_amplitude)\n",
    "\n",
    "    # 10. Feature extraction using hrvanalysis library\n",
    "    hrv_features  = extract_hrv_features(rr_intervals*1000)   # Convert RR intervals to milliseconds\n",
    "    features += list(hrv_features.values())\n",
    "\n",
    "    # Return the extracted feature vector\n",
    "    return features\n",
    "\n",
    "\n",
    "# Function to calculate Shannon entropy of a signal\n",
    "def signal_entropy(signal):\n",
    "    prob_density, _ = np.histogram(signal, bins=10, density=True)\n",
    "    prob_density = prob_density[prob_density > 0]  # Remove zero probabilities\n",
    "    entropy = -np.sum(prob_density * np.log(prob_density))  # Shannon entropy\n",
    "    return entropy\n",
    "\n",
    "\n",
    "# Time-domain statistical features (mean, std, skewness, kurtosis)\n",
    "def time_domain_features(signal):\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    skewness = skew(signal)\n",
    "    kurt = kurtosis(signal)\n",
    "    return [mean, std, skewness, kurt]\n",
    "\n",
    "# Feature extraction using hrvanalysis library\n",
    "\n",
    "def extract_hrv_features(rr_intervals):\n",
    "    \"\"\"\n",
    "    Extract HRV features using the hrvanalysis package.\n",
    "    \n",
    "    Args:\n",
    "    - rr_intervals: List of RR intervals in milliseconds.\n",
    "\n",
    "    Returns:\n",
    "    - features: Dictionary of HRV features.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time_features = hrvanalysis.get_time_domain_features(rr_intervals)\n",
    "        geometric_features = hrvanalysis.get_geometrical_features(rr_intervals)\n",
    "        frequency_features = hrvanalysis.get_frequency_domain_features(rr_intervals)\n",
    "        cscv_features = hrvanalysis.get_csi_cvi_features(rr_intervals)\n",
    "        poincare_features = hrvanalysis.get_poincare_plot_features(rr_intervals)\n",
    "        \n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    # Combine all features\n",
    "    features = {**time_features, **frequency_features, **poincare_features, **geometric_features, **cscv_features}\n",
    "    return features\n",
    "\n",
    "# Binned function for downsampling and applying a function over binned data\n",
    "def binned(x, y, xend, nbins, func):\n",
    "    bx = np.linspace(x[0], xend, nbins + 1)\n",
    "    idx = np.digitize(x, bx) - 1  # Bin assignments\n",
    "    bx = (bx[1:] + bx[:-1]) / 2  # Bin centers\n",
    "    by = np.array(\n",
    "        [func(y[idx == i]) for i in range(nbins)]\n",
    "    )  # Apply function to each bin\n",
    "    return bx, by\n",
    "\n",
    "\n",
    "# summary_stats function to compute statistical measures\n",
    "def summary_stats(x):\n",
    "    x = x[~np.isnan(x)]\n",
    "    if len(x) == 0:\n",
    "        return [0, 0, 0, 0]\n",
    "    else:\n",
    "        return [np.mean(x), np.std(x), np.median(x), np.var(x)]\n",
    "\n",
    "\n",
    "# Sequential feature engineering\n",
    "def feature_engineering(X):\n",
    "    \"\"\"\n",
    "    Sequentially process signals for feature engineering.\n",
    "    \n",
    "    Args:\n",
    "    - X: List or array of ECG signals.\n",
    "\n",
    "    Returns:\n",
    "    - X_features: Numpy array of extracted features.\n",
    "    \"\"\"\n",
    "    X_features = []\n",
    "    for signal in tqdm(X, desc=\"Feature Engineering\"):\n",
    "        features = _feature_engineering(signal)  # Call your existing feature extraction function\n",
    "        X_features.append(features)\n",
    "    return np.array(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "id": "GAerHtb1g_9W",
    "outputId": "0493d656-3419-43d0-c829-15bd0ef27c49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Engineering:   1%|          | 58/5117 [00:23<34:38,  2.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Do feature engineering\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_engineering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_raw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m feature_engineering(X_test_raw)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     X_train\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mX_test shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     X_test\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m      9\u001b[0m )\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mfeature_engineering\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    224\u001b[0m X_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m tqdm(X, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Engineering\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 226\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43m_feature_engineering\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call your existing feature extraction function\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     X_features\u001b[38;5;241m.\u001b[39mappend(features)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X_features)\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m_feature_engineering\u001b[1;34m(signal, method)\u001b[0m\n\u001b[0;32m      3\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Attempt using the first method\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     signals, info \u001b[38;5;241m=\u001b[39m \u001b[43mnk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mecg_process\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecg_signal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneurokit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurokit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\neurokit2\\ecg\\ecg_process.py:127\u001b[0m, in \u001b[0;36mecg_process\u001b[1;34m(ecg_signal, sampling_rate, method)\u001b[0m\n\u001b[0;32m    117\u001b[0m signals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m    118\u001b[0m     {\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mECG_Raw\u001b[39m\u001b[38;5;124m\"\u001b[39m: ecg_signal,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m     }\n\u001b[0;32m    124\u001b[0m )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Delineate QRS complex\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m delineate_signal, delineate_info \u001b[38;5;241m=\u001b[39m \u001b[43mecg_delineate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mecg_cleaned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecg_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrpeaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mECG_R_Peaks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_rate\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m info\u001b[38;5;241m.\u001b[39mupdate(delineate_info)  \u001b[38;5;66;03m# Merge waves indices dict with info dict\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Determine cardiac phases\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\neurokit2\\ecg\\ecg_delineate.py:164\u001b[0m, in \u001b[0;36mecg_delineate\u001b[1;34m(ecg_cleaned, rpeaks, sampling_rate, method, show, show_type, check, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m     waves \u001b[38;5;241m=\u001b[39m _ecg_delineator_cwt(\n\u001b[0;32m    161\u001b[0m         ecg_cleaned, rpeaks\u001b[38;5;241m=\u001b[39mrpeaks, sampling_rate\u001b[38;5;241m=\u001b[39msampling_rate\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdwt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscrete wavelet transform\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 164\u001b[0m     waves \u001b[38;5;241m=\u001b[39m \u001b[43m_dwt_ecg_delineator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecg_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrpeaks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeuroKit error: ecg_delineate(): \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcwt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdwt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\neurokit2\\ecg\\ecg_delineate.py:289\u001b[0m, in \u001b[0;36m_dwt_ecg_delineator\u001b[1;34m(ecg, rpeaks, sampling_rate, analysis_sampling_rate)\u001b[0m\n\u001b[0;32m    282\u001b[0m qpeaks_resampled \u001b[38;5;241m=\u001b[39m _dwt_resample_points(\n\u001b[0;32m    283\u001b[0m     qpeaks, sampling_rate, analysis_sampling_rate\n\u001b[0;32m    284\u001b[0m )\n\u001b[0;32m    286\u001b[0m tpeaks, ppeaks \u001b[38;5;241m=\u001b[39m _dwt_delineate_tp_peaks(\n\u001b[0;32m    287\u001b[0m     ecg, rpeaks_resampled, dwtmatr, sampling_rate\u001b[38;5;241m=\u001b[39manalysis_sampling_rate\n\u001b[0;32m    288\u001b[0m )\n\u001b[1;32m--> 289\u001b[0m qrs_onsets, qrs_offsets \u001b[38;5;241m=\u001b[39m \u001b[43m_dwt_delineate_qrs_bounds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrpeaks_resampled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdwtmatr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mppeaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtpeaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqpeaks_resampled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalysis_sampling_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m ponsets, poffsets \u001b[38;5;241m=\u001b[39m _dwt_delineate_tp_onsets_offsets(\n\u001b[0;32m    298\u001b[0m     ppeaks, rpeaks_resampled, dwtmatr, sampling_rate\u001b[38;5;241m=\u001b[39manalysis_sampling_rate\n\u001b[0;32m    299\u001b[0m )\n\u001b[0;32m    300\u001b[0m tonsets, toffsets \u001b[38;5;241m=\u001b[39m _dwt_delineate_tp_onsets_offsets(\n\u001b[0;32m    301\u001b[0m     tpeaks,\n\u001b[0;32m    302\u001b[0m     rpeaks_resampled,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     duration_onset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m,\n\u001b[0;32m    307\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\neurokit2\\ecg\\ecg_delineate.py:600\u001b[0m, in \u001b[0;36m_dwt_delineate_qrs_bounds\u001b[1;34m(rpeaks, dwtmatr, ppeaks, tpeaks, qpeaks, sampling_rate)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    599\u001b[0m epsilon_onset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39mdwt_local[onset_slope_peaks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mdwt_local\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43monset_slope_peaks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m epsilon_onset)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    601\u001b[0m     onsets\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do feature engineering\n",
    "X_train = feature_engineering(X_train_raw)\n",
    "X_test = feature_engineering(X_test_raw)\n",
    "print(\n",
    "    \"X_train shape: \",\n",
    "    X_train.shape,\n",
    "    \"\\nX_test shape\",\n",
    "    X_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL0UtVA9SSus"
   },
   "outputs": [],
   "source": [
    "# Save the data as npy to save time for later use\n",
    "np.save(f\"{fpath}feature_extraction/X_train.npy\", X_train)\n",
    "np.save(f\"{fpath}feature_extraction/X_test.npy\", X_test)\n",
    "np.save(f\"{fpath}feature_extraction/y_train.npy\", y_train_raw)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7FJrjrEJNK9B5XvGlhEKn",
   "include_colab_link": true,
   "mount_file_id": "1CqUKua_qbfR3gNJDGCuFdaz2O3TB_3nN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
